\chapter*{Závěr}
\addcontentsline{toc}{chapter}{Závěr}

V práci jsme nastínili principy dosavadních přístupů k extrakci melodie, uvedli výčet veřejně dostupných dat a vysvětlili způsoby evaluace. Na těchto základech jsme pak prezentovali experimentální výsledky nových architektur určených pro výpočet funkce salience s důrazem na odhad výšky tónů v nahrávkách, jejichž návrhy čerpají z příbuzných oborů a úloh. Následně jsme tyto architektury porovnali s vybranými state-of-the-art metodami. Ze tří navrhovaných dosáhla architektura HCNN na většině veřejně dostupných datasetech nejlepších výsledků. Architektura HCNN spočívá v duplikaci a vzájemném posunu výstupů vnitřních konvolučních vrstev takovým způsobem, aby následujícím konvolučním vrstvám umožnila lépe zachytit harmonické složky znějících tónů v signálu.

Východisek pro navazující práce je více. Jako nejsnadnější se jeví přidání libovolné techniky vyhlazování výstupů. V práci se zaměřujeme na výpočet funkce salience, výstup této funkce však dále nezpracováváme, obvyklým krokem metod extrakce melodie je tuto reprezentaci dále používat buď pro detekci kandidátních kontur melodie a z těch pak vybírat výslednou melodii nebo použít statistický model, který výstup vyhladí, další možností je použití rekurentních neuronových sítí, které by dovolilo současné trénování HCNN a tohoto modulu zahrnujícího kontext. Díky tomu by se tento modul mohl naučit v čase zohledňovat nejen výšky tónů, ale i barvu nástroje (čímž by se metoda začala podobat existujícím, úspěšným metodám modelující hlavní hlas v nahrávce, \cite{Durrieu2011a}). 

Dále je jistě možné se pokusit o zlepšení detekce melodie, ať už implementací složitějších systémů práhování nebo dokonce samostatného modulu pro detekci melodie. Při práci jsme zběžně testovali možnost použití nezávislé konvoluční sítě určené pouze pro detekci, jeho přesnost detekce však byla nižší, než pouhé práhování, výsledky jsme proto do práce již nezahrnovali. 

Je také možné upravovat architekturu HCNN --- pokoušet se dále zvětšovat kontext, nebo se naopak pokoušet ještě vylepšit základní bezkontextový model. Je možné experimentovat s vyššími konvolucemi (na frekvenční ose) pro zachycení závislostí mezi jednotlivými znějícími tóny, dále pak s méně často aplikovanou harmonickou transformací, která by dovolila trénování širších modelů, nebo například aplikace SpecAugment techniky nejen na vstupu sítě ale i uvnitř modelu jako speciální druh dropout regularizace. 

Techniky augmentace dat jsou jistě také směr, kterým se dá ubírat, protože se s ní spojuje možnost zvyšování kapacity modelu bez přeučení. Přidávání šumu do nahrávek je augmentační evergreen, který výsledky zlepší o několik desetin procentního bodu, žádná práce však nešla s augmentacemi příliš daleko. Možností je přitom více --- například používání rozmanitých audio efektů z programů pro skládání hudby nebo mixování exponenciálně velkého množství trénovacích dat pomocí jednotlivých monofonních stop z datasetů 

Jinou možností pokusu o řešení nedostatku dat je pomocí syntézy. Realistická syntéza dala například vzniknout novému klavírnímu datasetu MAESTRO \citep{Hawthorne2018a}, který svou délkou řádově předčil dosavadní datasety. Se zlepšujícími se generativními modely pro syntézu libovolných barev tónů \citep{Engel2019} se dá uvažovat o vzniku podobného datasetu i pro kompletní přepis nahrávek, a také pro přepis melodie.

Experimentovat lze samozřejmě i se vstupní reprezentací, například využitím zmiňované Fan Chirp Transform (\cite{Cancela2010}), která nabízí velmi dobré rozlišení frekvenčně modulovaných signálů, autokorelace výstupů banky filtrů (\cite{Paiva2006}), která je zatím nejblíže biologickým modelům lidského sluchu nebo využitím informace o fázi pro zpřesnění frekvečních odhadů a amplitud vrcholků spektra (Instantaneous Frequency, \cite{Dressler2009}).

Poslední možný směr, který předložímě je zmírnění vlivu malého množství dat pomocí multitask learningu. Díky přidání datasetů příbuzných úloh by bylo možné opět navýšit kapacitu modelů. Jako nejbližší se jeví úlohy kompletního přepisu hudby, tento směr již částečně prozkoumala \cite{Bittner2018}, případně oddělení signálů (source separation), o kterém publikované články nejsou. 

